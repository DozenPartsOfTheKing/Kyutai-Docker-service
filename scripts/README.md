## Скрипты `stt_from_file_pytorch.py` и `tts_pytorch.py`

В данном каталоге находятся два основных скрипта, демонстрирующих использование моделей **Kyutai STT** и **Kyutai TTS** в Python-окружении.

* **`stt_from_file_pytorch.py`** — потоковое распознавание речи из аудио-файла с возможностью вывода тайм-стемпов слов и (опционально) Semantic VAD.
* **`tts_pytorch.py`** — синтез речи на базе текстовых данных с выводом результата в файл WAV либо непосредственно на колонки в режиме реального времени.

---

### Быстрый старт

1. Установите зависимости (Python ≥ 3.12):

```bash
# классическим pip
pip install -r requirements.txt

# или через uv для воспроизводимых окружений
uv pip install -r requirements.txt
```

> **Примечание.** Для запуска на GPU убедитесь, что PyTorch собран с поддержкой нужной версии CUDA. При отсутствии GPU можно указать `--device cpu`, однако скорость будет заметно ниже.

2. Скачайте тестовый аудио-файл и текст:

```bash
# примеры уже лежат в репозитории
ls audio/bria.mp3       # пример для STT
ls text_to_say.txt      # пример для TTS
```

---

## `stt_from_file_pytorch.py`

### Запуск

```bash
uv run scripts/stt_from_file_pytorch.py \
    --hf-repo kyutai/stt-2.6b-en \
    audio/bria.mp3
```

### Обязательные параметры

| Параметр      | Описание                                                   |
|---------------|------------------------------------------------------------|
| `in_file`     | Путь до аудио-файла (любого формата, поддерживаемого `sphn`). |

### Опциональные параметры

| Параметр           | По-умолчанию | Описание |
|--------------------|--------------|----------|
| `--hf-repo`        | —            | Hugging Face-репозиторий с весами STT-модели. |
| `--tokenizer`      | —            | Локальный файл токенизатора. |
| `--moshi-weight`   | —            | Чекпойнт весов **LM** (Moshi). |
| `--mimi-weight`    | —            | Чекпойнт весов аудио-энкодера **Mimi**. |
| `--config-path`    | *None*       | Путь до TOML-конфига. |
| `--vad`            | *False*      | Включить Semantic Voice Activity Detection. |
| `--device`         | `cuda`       | Устройство (`cuda`, `cpu`, `mps`). |

### Что делает скрипт

1. Загружает модель, токенизатор и аудио-энкодер через `moshi`.
2. Ресэмплирует аудио к нужной частоте.
3. Передаёт аудио чанками в модель, выводя распознанные токены по мере готовности.
4. После окончания декодирует полученную последовательность в текст **с покадровыми тайм-стемпами слов**.

---

## `tts_pytorch.py`

### Запуск

```bash
# Воспроизведение через динамики (stdin → динамики)
echo "Привет, как дела?" | python scripts/tts_pytorch.py - -

# Генерация WAV-файла
python scripts/tts_pytorch.py text_to_say.txt output.wav
```

### Обязательные параметры

| Параметр | Описание |
|----------|----------|
| `inp`    | Входной текстовый файл **или** `-` для stdin. |
| `out`    | WAV-файл назначения **или** `-` для стриминга на аудиоустройство. |

### Опциональные параметры

| Параметр        | По-умолчанию                      | Описание |
|-----------------|-----------------------------------|----------|
| `--hf-repo`     | `kyutai/tts-1b-dsm` (см. код)     | Hugging Face-репозиторий с весами TTS. |
| `--voice-repo`  | `kyutai/tts-voices-dsm`           | Репозиторий с эмбеддингами голосов. |
| `--voice`       | `expresso/ex03-ex01_happy_001…`   | Путь к конкретному голосу внутри `voice-repo`. |
| `--device`      | `cuda`                            | Устройство (`cuda`, `cpu`, `mps`). |

### Что делает скрипт

1. Загружает модель **Kyutai TTS** и необходимые голосовые эмбеддинги.
2. Подготавливает «сценарий» (script) для озвучивания, поддерживается диалог нескольких реплик.
3. По кадрам генерирует аудиопоток.
   * Если `out == '-'` — кадры декодируются он-лайн и отправляются на `sounddevice` для воспроизведения.
   * Иначе — кадры объединяются и сохраняются в WAV.

---

## Полезные советы

* Для быстрой проверки моделей можно установить [**uv**](https://github.com/astral-sh/uv) и запускать скрипты так:

  ```bash
  uv run scripts/tts_pytorch.py - -
  ```

* Если у вас нет GPU, явно передайте `--device cpu`.
* Семплирование речи при стриминге происходит с задержкой ≈ 2,5 с (зависит от модели).
* Флаг `--vad` в STT-скрипте позволяет автоматически определять конец реплики пользователя — удобно для диалоговых систем.

